{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea87667",
   "metadata": {},
   "source": [
    "## Sci-Kit Documentation link "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e693e5f",
   "metadata": {},
   "source": [
    "https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqazZ6eHh6ZGY2VjdXZnNnRkVwQlRyckZjcmlQUXxBQ3Jtc0trVjlJYWlnQWpHUGdUV2ZLaFFyVGVYSlpsaUJ0QjNHemVGUkxtaS04a2M3Z3pXN05selQzN0pRM0xzeWtDdEEyVVN5VXZpdWd5QXFVNlNjbWNzU242c0xSMDl2TVgyYWdQMDBrNDhkX0ZURXJZR0dUaw&q=https%3A%2F%2Fscikit-learn.org%2Fstable%2Fdocumentation.html&v=M9Itm95JzL0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2354565",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25eeefb6",
   "metadata": {},
   "source": [
    "## Load all required Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6316f87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.  I was quite impressed and intrigued by the way that this solid storyline was developed, bringing the readers right into the world of the story.  I was engaged throughout and definitely enjoyed my time spent reading it.I loved the character development in this novel.  Da Silva creates a cast of high school students who actually act like high school students.  I really appreciated the fact that none of them were thrown into situations far beyond their years, nor did they deal with events as if they had decades of life experience under their belts.  It was very refreshing and added to the realism and impact of the novel.  The friendships between the characters in this novel were also truly touching.Overall, this novel was fantastic.  I can&#8217;t wait to read more and to find out what happens next in the series.  I&#8217;d definitely recommend this debut novel by Da Silva to those who want a little YA fun with a completely unique & shocking storyline.Please note that I received a complimentary copy of this work in exchange for an honest review.\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "#This is how we access the data from a json file\n",
    "import json\n",
    "\n",
    "file_name = './data/sentiment/books_small.json'\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line) #we load each line as json and store it\n",
    "        print(review['reviewText'])\n",
    "        # we extract only the required review text from the whole line\n",
    "        print(review['overall'])\n",
    "        # we print only the overall part from the review json object\n",
    "        # overall is displayed as 4.0\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39dc19c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the code below by making it a class\n",
    "class Sentiment: \n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "#Above class is an enum class\n",
    "\n",
    "class Review:\n",
    "    def __init__(self,text,score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #Score is 4 or 5\n",
    "            return Sentiment.POSITIVE\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c5c160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!', 4.0)\n",
      "Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "#store all the reviews as a list\n",
    "import json \n",
    "\n",
    "file_name = './data/sentiment/books_small.json'\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append((review['reviewText'],review['overall']))\n",
    "        #store both reviewText and overall rating as a tuple for each line\n",
    "        #this tuple is appended into reviews list for each line\n",
    "        \n",
    "#print a random tuple to verify that the data is appended\n",
    "print(reviews[5]) # - Entire tuple\n",
    "print(reviews[5][0]) # - The review\n",
    "print(reviews[5][1]) # - The overall raing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad84dbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!\n",
      "4.0\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "#instead of appending each element as tuple \n",
    "#append Review class objects so its easier to access\n",
    "#In this way the code is more clean\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))\n",
    "    \n",
    "print(reviews[5].text)\n",
    "print(reviews[5].score)\n",
    "print(reviews[5].sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63751862",
   "metadata": {},
   "source": [
    "## Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d88d868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1e1e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3405474",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43ba19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#use the func belowto split the data\n",
    "\n",
    "training, test = train_test_split(reviews,test_size=0.33,random_state=42)\n",
    "\n",
    "#test_size - 0.33 is testing data size and 0.67 is training\n",
    "#random_state is used to get the same data every time and not random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b8d2d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "895273e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee29c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "print(training[0].text)\n",
    "print(training[0].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69cd3721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "#split the text and sentiment into 2 seperate lists\n",
    "train_x = [x.text for x in training]\n",
    "train_y = [x.sentiment for x in training]\n",
    "\n",
    "test_x = [x.text for x in test]\n",
    "test_y = [x.sentiment for x in test]\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68c2e01",
   "metadata": {},
   "source": [
    "### For  machine learning models we need to conver the text data into numerical data so that its easier to create models\n",
    "### Best way to do this is to use BAGS OF WORDS in SKLEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c0ec04",
   "metadata": {},
   "source": [
    "## Bags of words Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a468206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer() \n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "#the above func fit_tranform does 2 things fit the data and tranform\n",
    "#another method is as shown below gives same output\n",
    "#vectorizer.fit(train_x)\n",
    "#train_x_vectors = vectorizer.tranform(train_x)\n",
    "\n",
    "#the above functions convert our train_x data into numeric vectors\n",
    "#for each sentence if there are occurances of selected words \n",
    "#we get a non zero value (indicating the number of occurances) and each sentence has a vector of its own\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())\n",
    "#it has nonzero value where ever we have an occurance of a useful word\n",
    "\n",
    "#we have 2 sets of data now\n",
    "#train_x_vectors for the text data \n",
    "#train_y for the review score\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "\n",
    "#we only transform and dont fit tranform in the case of test_x data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a784f0a",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b42a35d",
   "metadata": {},
   "source": [
    "### Linear SVM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3a2a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVM divides the dataset into 2 parts seperated by a linear line\n",
    "#both sides contain data from 2 different classes and are present on the 2 sides\n",
    "#the 2 classes are seperated using a single linear line hence the name linear SVM\n",
    "# SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64085703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every new Myke Cole book is better than the last, and this is no exception. If you haven't read the Shadow Ops series before start with Control Point, but go ahead and order Fortress Frontier and Breach Zone as well - you're going to want them.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "#we use a linear classifier in this case\n",
    "\n",
    "clf_svm.fit(train_x_vectors,train_y)\n",
    "\n",
    "print(test_x[0])\n",
    "\n",
    "clf_svm.predict(test_x_vectors[0])\n",
    "#we use the predict method on the test data vectors to predict the correct class label\n",
    "#as we can observe we get a positive prediction using the svm classifier\n",
    "#we can compare the test_x[0] data and the output to find that it is a positive review\n",
    "#so the classifier prediction is right and is positive for the first review in the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c90297",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e83114c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors,train_y)\n",
    "\n",
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9e6ba3",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fedd2e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# clf_gnb = GaussianNB()\n",
    "# clf_gnb.fit(train_x_vectors,train_y)\n",
    "\n",
    "# clf.gnb.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced93e85",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3af6c9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adi2b\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors,train_y)\n",
    "\n",
    "clf_log.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446ac577",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702cf83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

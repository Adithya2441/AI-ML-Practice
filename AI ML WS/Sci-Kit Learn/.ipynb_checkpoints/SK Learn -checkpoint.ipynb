{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea87667",
   "metadata": {},
   "source": [
    "## Sci-Kit Documentation link "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e693e5f",
   "metadata": {},
   "source": [
    "https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqazZ6eHh6ZGY2VjdXZnNnRkVwQlRyckZjcmlQUXxBQ3Jtc0trVjlJYWlnQWpHUGdUV2ZLaFFyVGVYSlpsaUJ0QjNHemVGUkxtaS04a2M3Z3pXN05selQzN0pRM0xzeWtDdEEyVVN5VXZpdWd5QXFVNlNjbWNzU242c0xSMDl2TVgyYWdQMDBrNDhkX0ZURXJZR0dUaw&q=https%3A%2F%2Fscikit-learn.org%2Fstable%2Fdocumentation.html&v=M9Itm95JzL0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2354565",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25eeefb6",
   "metadata": {},
   "source": [
    "## Load all required Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6316f87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.  I was quite impressed and intrigued by the way that this solid storyline was developed, bringing the readers right into the world of the story.  I was engaged throughout and definitely enjoyed my time spent reading it.I loved the character development in this novel.  Da Silva creates a cast of high school students who actually act like high school students.  I really appreciated the fact that none of them were thrown into situations far beyond their years, nor did they deal with events as if they had decades of life experience under their belts.  It was very refreshing and added to the realism and impact of the novel.  The friendships between the characters in this novel were also truly touching.Overall, this novel was fantastic.  I can&#8217;t wait to read more and to find out what happens next in the series.  I&#8217;d definitely recommend this debut novel by Da Silva to those who want a little YA fun with a completely unique & shocking storyline.Please note that I received a complimentary copy of this work in exchange for an honest review.\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "#This is how we access the data from a json file\n",
    "import json\n",
    "\n",
    "file_name = './data/sentiment/books_small.json'\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line) #we load each line as json and store it\n",
    "        print(review['reviewText'])\n",
    "        # we extract only the required review text from the whole line\n",
    "        print(review['overall'])\n",
    "        # we print only the overall part from the review json object\n",
    "        # overall is displayed as 4.0\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39dc19c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the code below by making it a class\n",
    "class Sentiment: \n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "#Above class is an enum class\n",
    "\n",
    "class Review:\n",
    "    def __init__(self,text,score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #Score is 4 or 5\n",
    "            return Sentiment.POSITIVE\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c5c160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!', 4.0)\n",
      "Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "#store all the reviews as a list\n",
    "import json \n",
    "\n",
    "file_name = './data/sentiment/books_small.json'\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append((review['reviewText'],review['overall']))\n",
    "        #store both reviewText and overall rating as a tuple for each line\n",
    "        #this tuple is appended into reviews list for each line\n",
    "        \n",
    "#print a random tuple to verify that the data is appended\n",
    "print(reviews[5]) # - Entire tuple\n",
    "print(reviews[5][0]) # - The review\n",
    "print(reviews[5][1]) # - The overall raing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad84dbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!\n",
      "4.0\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "#instead of appending each element as tuple \n",
    "#append Review class objects so its easier to access\n",
    "#In this way the code is more clean\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))\n",
    "    \n",
    "print(reviews[5].text)\n",
    "print(reviews[5].score)\n",
    "print(reviews[5].sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63751862",
   "metadata": {},
   "source": [
    "## Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d88d868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1e1e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3405474",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43ba19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#use the func belowto split the data\n",
    "\n",
    "training, test = train_test_split(reviews,test_size=0.33,random_state=42)\n",
    "\n",
    "#test_size - 0.33 is testing data size and 0.67 is training\n",
    "#random_state is used to get the same data every time and not random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b8d2d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "895273e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee29c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "print(training[0].text)\n",
    "print(training[0].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69cd3721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "#split the text and sentiment into 2 seperate lists\n",
    "train_x = [x.text for x in training]\n",
    "train_y = [x.sentiment for x in training]\n",
    "\n",
    "test_x = [x.text for x in test]\n",
    "test_y = [x.sentiment for x in test]\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68c2e01",
   "metadata": {},
   "source": [
    "### For  machine learning models we need to conver the text data into numerical data so that its easier to create models\n",
    "### Best way to do this is to use BAGS OF WORDS in SKLEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c0ec04",
   "metadata": {},
   "source": [
    "## Bags of words Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a468206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer() \n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "#the above func fit_tranform does 2 things fit the data and tranform\n",
    "#another method is as shown below gives same output\n",
    "#vectorizer.fit(train_x)\n",
    "#train_x_vectors = vectorizer.tranform(train_x)\n",
    "\n",
    "#the above functions convert our train_x data into numeric vectors\n",
    "#for each sentence if there are occurances of selected words \n",
    "#we get a non zero value (indicating the number of occurances) and each sentence has a vector of its own\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())\n",
    "#it has nonzero value where ever we have an occurance of a useful word\n",
    "\n",
    "#we have 2 sets of data now\n",
    "#train_x_vectors for the text data \n",
    "#train_y for the review score\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "\n",
    "#we only transform and dont fit tranform in the case of test_x data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a784f0a",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b42a35d",
   "metadata": {},
   "source": [
    "### Linear SVM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3a2a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVM divides the dataset into 2 parts seperated by a linear line\n",
    "#both sides contain data from 2 different classes and are present on the 2 sides\n",
    "#the 2 classes are seperated using a single linear line hence the name linear SVM\n",
    "# SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64085703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every new Myke Cole book is better than the last, and this is no exception. If you haven't read the Shadow Ops series before start with Control Point, but go ahead and order Fortress Frontier and Breach Zone as well - you're going to want them.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "#we use a linear classifier in this case\n",
    "\n",
    "clf_svm.fit(train_x_vectors,train_y)\n",
    "\n",
    "print(test_x[0])\n",
    "\n",
    "clf_svm.predict(test_x_vectors[0])\n",
    "#we use the predict method on the test data vectors to predict the correct class label\n",
    "#as we can observe we get a positive prediction using the svm classifier\n",
    "#we can compare the test_x[0] data and the output to find that it is a positive review\n",
    "#so the classifier prediction is right and is positive for the first review in the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c90297",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e83114c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors,train_y)\n",
    "\n",
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9e6ba3",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fedd2e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# clf_gnb = GaussianNB()\n",
    "# clf_gnb.fit(train_x_vectors,train_y)\n",
    "\n",
    "# clf.gnb.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced93e85",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3af6c9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adi2b\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors,train_y)\n",
    "\n",
    "clf_log.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446ac577",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7702cf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8242424242424242\n"
     ]
    }
   ],
   "source": [
    "# Evaluating our models for all the data by checking the accuracy\n",
    "# using svm\n",
    "print(clf_svm.score(test_x_vectors,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92e76f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7454545454545455\n"
     ]
    }
   ],
   "source": [
    "#using decision tree\n",
    "print(clf_dec.score(test_x_vectors,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0387c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using gaussian NB\n",
    "#print(clf_gnb.score(test_x_vectors,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98b0ad34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "#using log regression\n",
    "print(clf_log.score(test_x_vectors,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86a2f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Scores\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7cd9b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91319444, 0.21052632, 0.22222222])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for SVM\n",
    "f1_score(test_y,clf_svm.predict(test_x_vectors), average=None , labels = [Sentiment.POSITIVE, Sentiment.NEUTRAL , Sentiment.NEGATIVE])\n",
    "\n",
    "#f1 score means the weighted avg of precision and recall for the models\n",
    "#as we can see for the svm model the f1 score is good for positive predictions \n",
    "#but it is clearly not good for the negative and neutral predictions\n",
    "# F1 Score varies from 0 to 1 - Good to Bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a6de6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86017699, 0.09375   , 0.        ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for decision tree\n",
    "f1_score(test_y,clf_dec.predict(test_x_vectors), average=None , labels = [Sentiment.POSITIVE, Sentiment.NEUTRAL , Sentiment.NEGATIVE])\n",
    "\n",
    "# similar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "097407df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for GNB\n",
    "#f1_score(test_y,clf_gnb.predict(test_x_vectors), average=None , labels = [Sentiment.POSITIVE, Sentiment.NEUTRAL , Sentiment.NEGATIVE])\n",
    "\n",
    "# it also probably give a similar result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f8b9a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91370558, 0.12244898, 0.1       ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for log reg\n",
    "f1_score(test_y,clf_log.predict(test_x_vectors), average=None , labels = [Sentiment.POSITIVE, Sentiment.NEUTRAL , Sentiment.NEGATIVE])\n",
    "\n",
    "#similar results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df620174",
   "metadata": {},
   "source": [
    "## Improving our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e48e8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552\n",
      "47\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))\n",
    "print(train_y.count(Sentiment.NEUTRAL))\n",
    "\n",
    "#majority in our training data is positive hence the accuracy is more for only positive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9082ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "file_name = './data/sentiment/books_small_10000.json'\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append((review['reviewText'],review['overall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59b0dfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hoped for Mia to have some peace in this book, but her story is so real and raw.  Broken World was so touching and emotional because you go from Mia's trauma to her trying to cope.  I love the way the story displays how there is no \"just bouncing back\" from being sexually assaulted.  Mia showed us how those demons come for you every day and how sometimes they best you. I was so in the moment with Broken World and hurt with Mia because she was surrounded by people but so alone and I understood her feelings.  I found myself wishing I could give her some of my courage and strength or even just to be there for her.  Thank you Lizzy for putting a great character's voice on a strong subject and making it so that other peoples story may be heard through Mia's.\n",
      "5.0\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))\n",
    "    \n",
    "print(reviews[5].text)\n",
    "print(reviews[5].score)\n",
    "print(reviews[5].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f67150c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#use the func belowto split the data\n",
    "\n",
    "training, test = train_test_split(reviews,test_size=0.33,random_state=42)\n",
    "\n",
    "#test_size - 0.33 is testing data size and 0.67 is training\n",
    "#random_state is used to get the same data every time and not random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e572985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olivia Hampton arrives at the Dunraven family home as cataloger of their extensive library. What she doesn't expect is a broken carriage wheel on the way. Nor a young girl whose mind is clearly gone, an old man in need of care himself (and doesn&#8217;t quite seem all there in Olivia&#8217;s opinion). Furthermore, Marion Dunraven, the only sane one of the bunch and the one Olivia is inexplicable drawn to, seems captive to everyone in the dusty old house. More importantly, she doesn't expect to fall in love with Dunraven's daughter Marion.Can Olivia truly believe the stories of sadness and death that surround the house, or are they all just local neighborhood rumor?Was that carriage trouble just a coincidence or a supernatural sign to stay away? If she remains, will the Castle&#8217;s dark shadows take Olivia down with them or will she and Marion long enough to declare their love?Patty G. Henderson has created an atmospheric and intriguing story in her Gothic tale. I found this to be an enjoyable read, even if it isn&#8217;t my usual preferred genre. I think, with this tale, I got hooked on the old Gothic romantic style. So I think fans of the genre (and of lesbian romances) will enjoy it.\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "train_x = [x.text for x in training]\n",
    "train_y = [x.sentiment for x in training]\n",
    "\n",
    "test_x = [x.text for x in test]\n",
    "test_y = [x.sentiment for x in test]\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7b83743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olivia Hampton arrives at the Dunraven family home as cataloger of their extensive library. What she doesn't expect is a broken carriage wheel on the way. Nor a young girl whose mind is clearly gone, an old man in need of care himself (and doesn&#8217;t quite seem all there in Olivia&#8217;s opinion). Furthermore, Marion Dunraven, the only sane one of the bunch and the one Olivia is inexplicable drawn to, seems captive to everyone in the dusty old house. More importantly, she doesn't expect to fall in love with Dunraven's daughter Marion.Can Olivia truly believe the stories of sadness and death that surround the house, or are they all just local neighborhood rumor?Was that carriage trouble just a coincidence or a supernatural sign to stay away? If she remains, will the Castle&#8217;s dark shadows take Olivia down with them or will she and Marion long enough to declare their love?Patty G. Henderson has created an atmospheric and intriguing story in her Gothic tale. I found this to be an enjoyable read, even if it isn&#8217;t my usual preferred genre. I think, with this tale, I got hooked on the old Gothic romantic style. So I think fans of the genre (and of lesbian romances) will enjoy it.\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer() \n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "#We vectorize the new data now\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())\n",
    "\n",
    "#we have 2 sets of data now\n",
    "#train_x_vectors for the text data \n",
    "#train_y for the review score\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "\n",
    "#we only transform and dont fit tranform in the case of test_x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "037ce25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5611\n",
      "436\n",
      "653\n"
     ]
    }
   ],
   "source": [
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))\n",
    "print(train_y.count(Sentiment.NEUTRAL))\n",
    "\n",
    "#as you can see now there is more data for all the sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7989718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\"\"\"#Clean the code below by making it a class\n",
    "class Sentiment: \n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "#Above class is an enum class\n",
    "\n",
    "class Review:\n",
    "    def __init__(self,text,score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #Score is 4 or 5\n",
    "            return Sentiment.POSITIVE\n",
    "\"\"\"\n",
    "#Now we create another class called ReviewContainer\n",
    "class ReviewContainer:\n",
    "    def  __init__(self,reviews):\n",
    "        self.reviews=reviews\n",
    "    \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "            \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "        \n",
    "        \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x:x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x:x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        neutral = list(filter(lambda x:x.sentiment == Sentiment.NEUTRAL, self.reviews))\n",
    "\n",
    "        #we filter the data and store only the related data in each variable as indicated above using the filter method\n",
    "        #Now we shrink the positive data to match the number of the negative data\n",
    "        \n",
    "        positive_shrunk = positive[0:len(negative)]\n",
    "        self.reviews = negative+positive_shrunk\n",
    "        \n",
    "        #we change the self.reviews to the new shrunk data\n",
    "        \n",
    "        random.shuffle(self.reviews)\n",
    "        #we shuffle the data so that both negative and positive data are mixed\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "346615f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#use the func belowto split the data\n",
    "\n",
    "training, test = train_test_split(reviews,test_size=0.33,random_state=42)\n",
    "\n",
    "#test_size - 0.33 is testing data size and 0.67 is training\n",
    "#random_state is used to get the same data every time and not random data\n",
    "\n",
    "train_container = ReviewContainer(training)\n",
    "test_container = ReviewContainer(test)\n",
    "\n",
    "train_container.evenly_distribute()\n",
    "test_container.evenly_distribute()\n",
    "\n",
    "len(train_container.reviews)\n",
    "#we have the same amt of positive and negative data in our training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "44b4f2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n",
      "208\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "#Our data is now evenly distributed both train and test data\n",
    "\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))\n",
    "\n",
    "print(test_y.count(Sentiment.POSITIVE))\n",
    "print(test_y.count(Sentiment.NEGATIVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "00f0e490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really like this book in preparing kids that if anything should happen you should yell and tell. its great in letting them know that its not their fault and they haven't done anything wrong.\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer() \n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "#We vectorize the new data now\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())\n",
    "\n",
    "#we have 2 sets of data now\n",
    "#train_x_vectors for the text data \n",
    "#train_y for the review score\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "\n",
    "#we only transform and dont fit tranform in the case of test_x data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525e51e8",
   "metadata": {},
   "source": [
    "### Classification of the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "03b3f096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book is twisted in the abuse put forth against Sarah, by her boss Travis. It is almost a classic case of the victim falling in love with her abuser. Yes, this is abuse, due to the fact that it is not consensual with both parties. You don't force someone to marry you, especially when they are insecure with themselves and life in general.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors,train_y)\n",
    "\n",
    "print(test_x[0])\n",
    "\n",
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e156bfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors,train_y)\n",
    "\n",
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c97ddc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GNB\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# clf_gnb = GaussianNB()\n",
    "# clf_gnb.fit(train_x_vectors,train_y)\n",
    "\n",
    "# clf.gnb.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f49d48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Log Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors,train_y)\n",
    "\n",
    "clf_log.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd1527c",
   "metadata": {},
   "source": [
    "#### SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "92355b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980769230769231\n",
      "0.6418269230769231\n",
      "0.8149038461538461\n"
     ]
    }
   ],
   "source": [
    "print(clf_svm.score(test_x_vectors,test_y))\n",
    "print(clf_dec.score(test_x_vectors,test_y))\n",
    "#print(clf_gnb.score(test_x_vectors,test_y))\n",
    "print(clf_log.score(test_x_vectors,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e546d525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8028169 , 0.79310345])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_y,clf_svm.predict(test_x_vectors), average=None , labels = [Sentiment.POSITIVE, Sentiment.NEGATIVE])\n",
    "#f1_score(test_y,clf_dec.predict(test_x_vectors), average=None , labels = [Sentiment.POSITIVE, Sentiment.NEGATIVE])\n",
    "#f1_score(test_y,clf_gnb.predict(test_x_vectors), average=None , labels = [Sentiment.POSITIVE, Sentiment.NEGATIVE])\n",
    "#f1_score(test_y,clf_log.predict(test_x_vectors), average=None , labels = [Sentiment.POSITIVE, Sentiment.NEGATIVE])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefb689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
